trigger: none
pr:
  branches:
    include: [ main ]
  autoCancel: true
  drafts: true

jobs:

  - job: nbval
    # how long to run the job before automatically cancelling
    timeoutInMinutes: 55
    # how much time to give 'run always even if cancelled tasks' before stopping them
    cancelTimeoutInMinutes: 2

    pool: gridai-spot-pool
    # this need to have installed docker in the base image...
    container:
      # base ML image: mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04
      image: "pytorchlightning/pytorch_lightning:base-cuda-py3.9-torch1.8"
      # image: "pytorch/pytorch:1.7.1-cuda11.0-cudnn8-runtime"
      options: "-it --rm --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=all --shm-size=32g"

    variables:
      ACCELERATOR: CPU,GPU
      PATH_DATASETS: "$(Build.Repository.LocalPath)/.datasets"

    steps:

    - bash: |
        lspci | egrep 'VGA|3D'
        whereis nvidia
        nvidia-smi
        python --version
      displayName: 'Image info & NVIDIA'

    - bash: |
        pip --version
        pip install --requirement requirements.txt
        pip list
      displayName: 'Install dependencies'

    - bash: |
        python -c "import torch ; mgpu = torch.cuda.device_count() ; assert mgpu > 0, f'GPU: {mgpu}'"
      displayName: 'Sanity check'

    - bash: |
        head=$(git rev-parse origin/main)
        printf "Head: $head\n"
        git diff --name-only $head --output=target-diff.txt
        python .actions/helpers.py group-folders target-diff.txt
        printf "Changed folders:\n"
        cat changed-folders.txt
      displayName: 'Process folders'

    - script: |
        COUNT=$(python -c "lines = open('changed-folders.txt').readlines() ; print(len(lines))")
        printf "Changed folders: $COUNT\n"
        echo "##vso[task.setvariable variable=folders;isOutput=true]$COUNT"
      name: changed

    - task: Cache@2
      inputs:
        key: data | .actions/data-download.sh
        restoreKeys: data
        path: $(PATH_DATASETS)
        cacheHitVar: DATA_RESTORED

    - script: bash .actions/data-download.sh $(PATH_DATASETS)
      condition: ne(variables.DATA_RESTORED, 'true')
      displayName: 'Pull datasets'

    - bash: |
        while IFS= read -r line; do
            bash .actions/ipynb-generate.sh $line
        done <<< $(cat changed-folders.txt)
      condition: gt(variables['changed.folders'], 0)
      displayName: 'Generate notebook'

    - bash: |
        while IFS= read -r line; do
            bash .actions/ipynb-test.sh $line
        done <<< $(cat changed-folders.txt)
      condition: and(succeeded(), gt(variables['changed.folders'], 0))
      displayName: 'PyTest notebook'
